1、ROCKETMQ架构设计原理
    nameServer:注册中心、用于broke管理和topic路由信息注册。
    BROKER:消息服务器，在启动时会向所有nameServer注册。
    producer:在发送消息前会先从nameServer获取broke服务器列表，根据负载均衡获取
    一台进行消息发送。
    consumer:与nameserver的一台保持长连接，定期或者topic路由信息,向提供topic的master和slave建立
    长连接，可以从master拉取消费也可以是slave.

2、MQ选型，为什么选择ROCKETMQ
    数据可靠性：
        1、RocketMQ有异步刷盘和同步刷盘，同步刷盘不会因为crash导致消息丢失
        2、Kafka只有异步刷盘，异步复制,crash会丢失还未持久化的数据

    性能：
        1、Kafka单机几百万TPS主要是producer将多个消息合并，批量发送，当produced宕机会丢数据
        RocketMQ 单机几W
        为什么RocketMq不这么做
        1、RocketMQ纯java，合并缓存大量消息可能GC频繁影响性能
        2、缓存消息如果producer宕机会丢失数据
        
    队列：kafka单机超过64个队列，会出现明显的load变高、发送消息响应时间变长的情况。【producer会为每个分区缓存消息，当满了就发送，
    分区数多，缓存的量就大】
        rocketmq单机支持最高5W个队列，性能没什么变化。
        队列多的好处：
        1、可以创建更多的topic。每个topic由一批队列组成
    
    重试：
    kafka消费失败不支持重试，rocketmq支持重试

    消费顺序：
    1、kafka支持顺序消费，一个broken宕机会造成消息乱序
    2、rocketmq支持顺序消费，一个broken宕机会丢数据

    定时消息：
    1、kafka不支持定时消息
    2、rocketmq支持定时消息

    消息过滤：
    1、kafka不支持broke端消息过滤
    2、rocketmq支持broke消息过滤

    消费并行度：
    1、kafka并行度和分区数一致，有多少个分区就有多少个线程消费
    2、rocketmq的并行度有消费端开的线程数决定

3、NameServer问题记录？
    NameServer路由元信息保存了什么数据？
        1、topic消息队列路由信息
        2、broker信息
        3、broker集群信息
        4、broker状态信息
        5、FilterServer列表
    路由注册和剔除原理？
    路由注册：broker启动时像集群内所有的namesever,每隔30s向集群内的nameserver发送心跳包，
    nameServer收到心跳包更新该broke最近更新时间
    路由剔除：
    1、broker正常关闭，执行路由剔除
    2、nameserver每隔10s删除已经2分钟没有心跳的broker信息。

    路由发现原理？
    rocketmq的路由是非实时的。当topic路由发生变化，不会主动推送给客户端。客户端根据topic名称
    主动向nameserver拉取。
    用nameServer优缺点，为什么不用ZK
    1、性能：nameserver可以容易的无限扩展，服务之间没有关联，不存在zk的强一致性，需要选举，会影响到性能，和高可用
    2、存储：nameserver存储路由信息依赖心跳上报，不需要持久化。用不到也没必要zk的持久化
4、消息发送原理？
    消息发送三种方式：
        同步：向服务器发送消息等待结果返回
        异步：向服务器发送消息立马返回，消息发送成功或者失败的回调任务在新的线程中执行。
        单向：只管发送，不管是否发送成功。
    发送消息的步骤：
        1、验证消息
            是否符合规范，主题名称、消息体不能为空，消息长度小于4M
        2、查找路由
            查找路由信息、选择消息队列
        3、发送消息。
    
    选择消息队列的方式：
        1、不启用故障延时。 轮询选择消息队列，过滤掉不可用的broker
        2、启用故障延时。过滤掉MQ认为不可用的broker，避免不断向不可用的broker发消息。
    
    消息高可用发送的机制：
    1、重试
    2、故障延时
    
5、消息发送存储流程？
    COMMITLOG:顺序写入存储所有消息。
    ConsumeQueue:消息消费队列。写入commitLog后异步转发，供消费者消费。
    IndexFile:索引文件，存储消息key与offset的关系。

    MappedFile：映射文件
    MappedFileQueue:映射文件队列。好比目录。

    MappedFile是否开启堆外内存：
    true:先写入堆外内存，然后通过commit线程提交到内存映射buffer，然后定时flush
    false:直接写入pageCache，然后定时flush

    TransientStorePool:
    堆外内存，用于临时存储消息，并且有内存锁定，避免将这部分内存交换到磁盘，影响到性能。


7、索引文件恢复原理？
    RocketMQ文件 COMMITLOG/CONSUMEQUEUE/INDEXFILE 
    先写入commitlog，在转发到消息队列和索引文件。
    如果在写入了commitlog，消息队列和索引文件还未同步时宕机就会出现数据不同步的情况。
    通过abort文件来判断是否正常关机，在abort正常运行时会创建一个abort文件，在关机时会删除该文件，
    如果文件没有删除，可以认为是异常关机的。
    异常关机的在启动时查询checkpoint记录的刷盘记录。
    从后往前扫描commitlog，判断commitlog的起始游标，从第一个起始游标小于刷盘游标的文件开始恢复。
    可能会重复发送消息，因此消费端需要做好幂等。
8、文件刷盘机制？
    同步刷盘：消息追加到映射文件的内存后，立马flush到磁盘。flush成功后返回响应给客户端。
    异步刷盘：是否开启堆外内存，如果开启了。，先写入堆外内存，在通过commit线程定时提交到内存映射buffer，在定时flush.
            没有开启的话。直接追加的到文件映射的buffer上，在定时flush
9、过期文件删除机制？
    机制：非当前写文件，且长时间（默认72H）没有更新则通过定时扫描 或者磁盘不足时 删除。
10、消息消费流程
    广播模式：主题下的同一条消息会被消费组内所有的消费者消费。 消费进度保存在消费者。
    集群模式：主题下的同一条消息只被一个消费者消费，消息进度保存在broker.

    消息的推其实就是拉模式。由消息消费者拉取broker服务器的消息放入本地消费队列，再由消费者的线程池执行消费。
11、定时消费机制
    延迟消费的原理，是将延迟消息存入一个定时TOPIC主题中，定时调度查询任务，符合条件的消息进行恢复，写入commitlog，在转发到对应主题的
    消费队列供消费者消费。
12、消息过滤原理
    消息消费队列存储了tag的hashcode,消费者拉消息的时候，比较hashcode,匹配的就拉取消费。
13、顺序消费原理
    支持局部顺序消费，同一个队列，单线程消费者的消息消费是顺序的。要全局有序，需要将队列设置成1，影响消费速率。
    在消息队列重新分配后，消费者需要先尝试或者队列的锁，或者到再执行消费，保证顺序。
14、RocketMq主从复制原理
    消息到达主服务器后，从服务器或者主服务器的最大偏移量，需要将消息
    同步阻塞复制到从服务器，从服务器全部复制完，消息发送端才会响应成功，如果主服务器无法使用，消费者可以从从服务器拉取消息。
    
15、RocketMq读写分离原理
    首先从主服务器拉取数据，主服务器返回消息后，再根据负载情况决定从哪个服务器拉取。
16、RocketMq事务
    消息发送端发送prepare消息到broker,备份原消息主题和队列，将消息放入到一个特定主题的消息队列。
    然后通知发送端执行后面的逻辑，执行成功将消息放入真正的消息队列，失败就回滚，
17、RocketMQ应用场景
    异步、削锋、解耦

18、如何保证消息不丢失
    1、同步发送消息
    2、发送失败重试
    3、多master机制，有宕机就转移
    4、同步刷盘
    5、主从同步双写

19、如果保证消息幂等
    消费端控制。
    全局消息id缓存，业务判断
22、消息堆积怎么处理
    1、消息会定时删除、消息堆积过大会删除消息
    2、不同业务的拒绝策略
    3、消息转移，重要消息落库
23、高吞吐量下如何优化生产者和消费者的性能?
    同一个group，多机部署，并发消费。
    消费者提高线程数
    批量消费，业务逻辑批量处理等。
    


